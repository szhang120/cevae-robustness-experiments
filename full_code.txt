Directory Tree:
cevae-robustness-experiments/
│   ├── .DS_Store
│   ├── models.py
│   ├── latent_conf_ihdp.py
│   ├── pca_shift_ihdp.py
│   ├── train_test.py
│   ├── cs229_poster2.png
│   ├── README.md
│   ├── pca_shift_ihdp_modified.py
│   ├── full_code.txt
│   ├── utils.py
│   ├── main.py
│   ├── visual_cevae.py
│   ├── cs229_final_report.pdf
│   ├── analyze_shifts.py
│   ├── shift_pca.py
│   ├── data.py
│   ├── final_dashboard.png
│   ├── contrast_plots/
│   │   ├── dmar_contrast.png
│   │   ├── dlivord_min_contrast.png
│   │   ├── birattnd_contrast.png
│   │   ├── nprevistq_contrast.png
│   │   ├── mager8_contrast.png
│   │   ├── brstate_contrast.png
│   │   ├── mplbir_contrast.png
│   │   ├── bord_contrast.png
│   │   ├── renal_contrast.png
│   │   ├── dtotord_min_contrast.png
│   │   ├── feduc6_contrast.png
│   │   ├── chyper_contrast.png
│   │   ├── tobacco_contrast.png
│   │   ├── mpre5_contrast.png
│   │   ├── lung_contrast.png
│   │   ├── orfath_contrast.png
│   │   ├── uterine_contrast.png
│   │   ├── preterm_contrast.png
│   │   ├── data_year_contrast.png
│   │   ├── crace_contrast.png
│   │   ├── phyper_contrast.png
│   │   ├── drink5_contrast.png
│   │   ├── hydra_contrast.png
│   │   ├── diabetes_contrast.png
│   │   ├── incervix_contrast.png
│   │   ├── csex_contrast.png
│   │   ├── cigar6_contrast.png
│   │   ├── herpes_contrast.png
│   │   ├── eclamp_contrast.png
│   │   ├── ormoth_contrast.png
│   │   ├── alcohol_contrast.png
│   │   ├── adequacy_contrast.png
│   │   ├── meduc6_contrast.png
│   │   ├── anemia_contrast.png
│   │   ├── hemo_contrast.png
│   │   ├── birmon_contrast.png
│   │   ├── pre4000_contrast.png
│   │   ├── cardiac_contrast.png
│   │   ├── dfageq_contrast.png
│   │   ├── mrace_contrast.png
│   │   ├── rh_contrast.png
│   │   ├── pldel_contrast.png
│   │   ├── stoccfipb_contrast.png
│   ├── shift_analysis_plots/
│   │   ├── distribution_pre4000.png
│   │   ├── distribution_uterine.png
│   │   ├── distribution_dtotord_min.png
│   │   ├── distribution_lung.png
│   │   ├── distribution_data_year.png
│   │   ├── distribution_eclamp.png
│   │   ├── distribution_dlivord_min.png
│   │   ├── distribution_feduc6.png
│   │   ├── distribution_mrace.png
│   │   ├── distribution_csex.png
│   │   ├── distribution_meduc6.png
│   │   ├── distribution_x8.png
│   │   ├── distribution_x15.png
│   │   ├── distribution_ormoth.png
│   │   ├── distribution_x14.png
│   │   ├── distribution_x16.png
│   │   ├── distribution_rh.png
│   │   ├── distribution_preterm.png
│   │   ├── distribution_x17.png
│   │   ├── distribution_x13.png
│   │   ├── distribution_x12.png
│   │   ├── distribution_orfath.png
│   │   ├── distribution_stoccfipb.png
│   │   ├── distribution_renal.png
│   │   ├── distribution_cardiac.png
│   │   ├── distribution_x10.png
│   │   ├── distribution_x11.png
│   │   ├── distribution_x20.png
│   │   ├── distribution_x21.png
│   │   ├── distribution_adequacy.png
│   │   ├── distribution_phyper.png
│   │   ├── distribution_cigar6.png
│   │   ├── distribution_birmon.png
│   │   ├── distribution_x23.png
│   │   ├── distribution_birattnd.png
│   │   ├── distribution_x22.png
│   │   ├── distribution_pldel.png
│   │   ├── distribution_crace.png
│   │   ├── distribution_mager8.png
│   │   ├── distribution_anemia.png
│   │   ├── distribution_mpre5.png
│   │   ├── distribution_x25.png
│   │   ├── distribution_x19.png
│   │   ├── distribution_x18.png
│   │   ├── distribution_x24.png
│   │   ├── distribution_x4.png
│   │   ├── distribution_brstate.png
│   │   ├── distribution_x5.png
│   │   ├── distribution_hemo.png
│   │   ├── distribution_dmar.png
│   │   ├── distribution_mplbir.png
│   │   ├── distribution_dfageq.png
│   │   ├── distribution_diabetes.png
│   │   ├── distribution_x7.png
│   │   ├── distribution_hydra.png
│   │   ├── distribution_bord.png
│   │   ├── distribution_tobacco.png
│   │   ├── distribution_x6.png
│   │   ├── distribution_chyper.png
│   │   ├── distribution_herpes.png
│   │   ├── distribution_x2.png
│   │   ├── distribution_x3.png
│   │   ├── distribution_nprevistq.png
│   │   ├── distribution_alcohol.png
│   │   ├── distribution_x1.png
│   │   ├── distribution_incervix.png
│   │   ├── distribution_drink5.png
│   ├── target_shift_plots/
│   │   ├── before_after_stoccfipb.png
│   ├── __pycache__/ [EXCLUDED]
│   ├── pca_shift_plots/
│   │   ├── PC10_before_after.png
│   │   ├── PC8_before_after.png
│   │   ├── PC3_before_after.png
│   │   ├── PC7_before_after.png
│   │   ├── PC21_before_after.png
│   │   ├── PC14_before_after.png
│   │   ├── PC9_before_after.png
│   │   ├── PC11_before_after.png
│   │   ├── PC2_before_after.png
│   │   ├── PC24_before_after.png
│   │   ├── PC20_before_after.png
│   │   ├── PC6_before_after.png
│   │   ├── PC15_before_after.png
│   │   ├── PC2_distribution.png
│   │   ├── PC1_before_after.png
│   │   ├── PC19_before_after.png
│   │   ├── PC12_before_after.png
│   │   ├── PC16_before_after.png
│   │   ├── PC23_before_after.png
│   │   ├── PC5_before_after.png
│   │   ├── PC18_before_after.png
│   │   ├── PC13_before_after.png
│   │   ├── PC17_before_after.png
│   │   ├── PC4_before_after.png
│   │   ├── PC22_before_after.png
│   ├── random_visuals/
│   │   ├── 1_final_dashboard.png
│   │   ├── final_visualization.png
│   │   ├── final_dashboard.png
│   │   ├── __pycache__/ [EXCLUDED]
│   ├── all_shift_plots/
│   │   ├── before_after_diabetes.png
│   │   ├── before_after_herpes.png
│   │   ├── before_after_chyper.png
│   │   ├── before_after_dfageq.png
│   │   ├── before_after_data_year.png
│   │   ├── before_after_mplbir.png
│   │   ├── before_after_incervix.png
│   │   ├── before_after_hydra.png
│   │   ├── before_after_drink5.png
│   │   ├── before_after_birattnd.png
│   │   ├── before_after_pldel.png
│   │   ├── before_after_crace.png
│   │   ├── before_after_bord.png
│   │   ├── before_after_mpre5.png
│   │   ├── before_after_alcohol.png
│   │   ├── before_after_adequacy.png
│   │   ├── before_after_birmon.png
│   │   ├── before_after_cigar6.png
│   │   ├── before_after_hemo.png
│   │   ├── before_after_dmar.png
│   │   ├── before_after_phyper.png
│   │   ├── before_after_anemia.png
│   │   ├── before_after_mager8.png
│   │   ├── before_after_dtotord_min.png
│   │   ├── before_after_tobacco.png
│   │   ├── before_after_brstate.png
│   │   ├── before_after_dlivord_min.png
│   │   ├── before_after_stoccfipb.png
│   │   ├── before_after_lung.png
│   │   ├── before_after_ormoth.png
│   │   ├── before_after_renal.png
│   │   ├── before_after_orfath.png
│   │   ├── before_after_rh.png
│   │   ├── before_after_uterine.png
│   │   ├── before_after_pre4000.png
│   │   ├── before_after_csex.png
│   │   ├── before_after_cardiac.png
│   │   ├── before_after_mrace.png
│   │   ├── before_after_eclamp.png
│   │   ├── before_after_preterm.png
│   │   ├── before_after_nprevistq.png
│   │   ├── before_after_feduc6.png
│   │   ├── before_after_meduc6.png
│   ├── .git/ [EXCLUDED]
│   ├── data/
│   │   ├── .DS_Store
│   │   ├── c
│   │   ├── TWINS/
│   │   │   ├── top_correlated_covariates.csv
│   │   │   ├── processed_y.csv
│   │   │   ├── processed_X_covariate_shifted.csv
│   │   │   ├── processed_X.csv
│   │   │   ├── processed_X_indexed.csv
│   │   │   ├── processed_X_stoccfipb.csv
│   │   │   ├── processed_X_44.csv
│   │   │   ├── processed_t.csv
│   │   │   ├── processed_z_p0.3.csv
│   │   │   ├── processed_z_p0.2.csv
│   │   │   ├── processed_z_p0.0.csv
│   │   │   ├── processed_z_p0.1.csv
│   │   │   ├── processed_z_p0.5.csv
│   │   │   ├── processed_X_allshifted.csv
│   │   │   ├── processed_z_p0.4.csv
│   │   │   ├── processed_X_pca_shifted.csv
│   │   ├── IHDP/
│   │   │   ├── .DS_Store
│   │   │   ├── columns.txt
│   │   │   ├── processed_X_ihdp_modified.csv
│   │   │   ├── processed_Z_pca.csv
│   │   │   ├── processed_Z_ihdp_p0.1.csv
│   │   │   ├── processed_Z_ihdp_p0.3.csv
│   │   │   ├── processed_Z_ihdp_p0.2.csv
│   │   │   ├── processed_X_pca_shifted.csv
│   │   │   ├── processed_Z_ihdp_p0.5.csv
│   │   │   ├── processed_Z_ihdp_p0.4.csv
│   │   │   ├── csv/
│   │   │   │   ├── concatenated_ihdp.csv
│   │   │   │   ├── ihdp_npci_5.csv
│   │   │   │   ├── ihdp_npci_4.csv
│   │   │   │   ├── ihdp_npci_6.csv
│   │   │   │   ├── ihdp_npci_7.csv
│   │   │   │   ├── ihdp_npci_3.csv
│   │   │   │   ├── ihdp_npci_2.csv
│   │   │   │   ├── ihdp_npci_1.csv
│   │   │   │   ├── ihdp_npci_10.csv
│   │   │   │   ├── ihdp_npci_9.csv
│   │   │   │   ├── ihdp_npci_8.csv
│   ├── contrast_ihdp_plots/
│   │   ├── x18_contrast.png
│   │   ├── x19_contrast.png
│   │   ├── x6_contrast.png
│   │   ├── x1_contrast.png
│   │   ├── x22_contrast.png
│   │   ├── x25_contrast.png
│   │   ├── x13_contrast.png
│   │   ├── x14_contrast.png
│   │   ├── x24_contrast.png
│   │   ├── x23_contrast.png
│   │   ├── x7_contrast.png
│   │   ├── x15_contrast.png
│   │   ├── x12_contrast.png
│   │   ├── x21_contrast.png
│   │   ├── x5_contrast.png
│   │   ├── x2_contrast.png
│   │   ├── x10_contrast.png
│   │   ├── x17_contrast.png
│   │   ├── x3_contrast.png
│   │   ├── x4_contrast.png
│   │   ├── x20_contrast.png
│   │   ├── x16_contrast.png
│   │   ├── x11_contrast.png
│   │   ├── x8_contrast.png




# ======================
# File: models.py
# ======================

import torch
import pyro
from visual_cevae import VisualCEVAE

class CEVAEWithZ(VisualCEVAE):
    """
    Extends the visual CEVAE (VisualCEVAE) by appending Z to X during training and inference.
    """
    def fit(self, x, t, y, z, **kwargs):
        x_extended = torch.cat([x, z], dim=1)
        return super().fit(x_extended, t, y, **kwargs)

    def ite(self, x, z):
        x_extended = torch.cat([x, z], dim=1)
        return super().ite(x_extended)


# ======================
# File: latent_conf_ihdp.py
# ======================

#!/usr/bin/env python3
"""
latent_conf_ihdp.py

This script processes the IHDP concatenated CSV (with 25 covariates) to extract a latent confounder.
It performs the following:
  1. Identifies the ordinal covariate (among x1 ... x25) that is most correlated with the continuous outcome y_factual.
  2. One–hot encodes that covariate.
  3. Replicates the one–hot encoding three times and pads/trims to create a 30-dimensional vector.
  4. For each flipping probability p in {0.1, 0.2, 0.3, 0.4, 0.5}, flips each bit with probability p
     to create five noisy versions of the latent confounder Z.
  5. Removes the selected covariate from the original set, saving a modified covariate dataset with 24 columns.
"""

import os
import argparse
import pandas as pd
import numpy as np
from scipy.stats import pearsonr

def is_ordinal(values, tol=1e-5):
    """Return True if all values are nearly integers."""
    return np.allclose(values, np.round(values), atol=tol)

def main():
    parser = argparse.ArgumentParser(
        description="Extract the most correlated ordinal covariate as a latent confounder Z and remove it from X."
    )
    parser.add_argument("--input-file", type=str, default="data/IHDP/csv/concatenated_ihdp.csv",
                        help="Path to the IHDP concatenated CSV file.")
    parser.add_argument("--output-x", type=str, default="data/IHDP/processed_X_ihdp_modified.csv",
                        help="Path to save modified IHDP covariates (24 columns).")
    parser.add_argument("--output-z-prefix", type=str, default="data/IHDP/processed_Z_ihdp",
                        help="Output prefix for latent confounder Z datasets. (Suffix will include flip probability.)")
    args = parser.parse_args()

    # Load the concatenated IHDP CSV.
    df = pd.read_csv(args.input_file)
    expected_cols = ["treatment", "y_factual", "y_cfactual", "mu0", "mu1"] + [f"x{i}" for i in range(1,26)]
    for col in expected_cols:
        if col not in df.columns:
            raise ValueError(f"Missing expected column: {col}")

    # Outcome is y_factual.
    outcome = df["y_factual"].values.astype(float)

    # Identify ordinal covariates among x1...x25.
    ordinal_corr = {}
    for i in range(1,26):
        col = f"x{i}"
        values = df[col].values.astype(float)
        if is_ordinal(values):
            corr, _ = pearsonr(values, outcome)
            ordinal_corr[col] = abs(corr)
    if not ordinal_corr:
        raise ValueError("No ordinal covariate found among x1...x25.")
    # Select the ordinal covariate with highest absolute correlation.
    selected_cov = max(ordinal_corr, key=ordinal_corr.get)
    print("Selected ordinal covariate:", selected_cov, "with absolute correlation:", ordinal_corr[selected_cov])

    # One-hot encode the selected covariate.
    selected_values = df[selected_cov].values.astype(int)
    categories = np.unique(selected_values)
    one_hot = np.zeros((len(selected_values), len(categories)), dtype=int)
    for idx, cat in enumerate(categories):
        one_hot[:, idx] = (selected_values == cat).astype(int)
    
    # Replicate the one-hot encoding three times.
    replicated = np.tile(one_hot, (1, 3))
    d = replicated.shape[1]
    # Trim or pad to 30 dimensions.
    if d > 30:
        replicated = replicated[:, :30]
    elif d < 30:
        pad_width = 30 - d
        replicated = np.hstack([replicated, np.zeros((replicated.shape[0], pad_width), dtype=int)])
    
    # Generate five versions of Z by flipping bits with probability p.
    flip_ps = [0.1, 0.2, 0.3, 0.4, 0.5]
    for p in flip_ps:
        noisy_Z = replicated.copy()
        flip_mask = np.random.rand(*noisy_Z.shape) < p
        noisy_Z[flip_mask] = 1 - noisy_Z[flip_mask]
        out_file = f"{args.output_z_prefix}_p{p}.csv"
        pd.DataFrame(noisy_Z, columns=[f"z{i+1}" for i in range(noisy_Z.shape[1])]).to_csv(out_file, index=False)
        print(f"Noisy latent confounder Z with p={p} saved to: {out_file}")

    # Remove the selected covariate from X.
    covariate_cols = [f"x{i}" for i in range(1,26)]
    remaining_covs = [col for col in covariate_cols if col != selected_cov]
    modified_X = df[remaining_covs]
    modified_X.to_csv(args.output_x, index=False)
    print(f"Modified IHDP covariate dataset (24 covariates) saved to: {args.output_x}")

if __name__ == "__main__":
    main()


# ======================
# File: pca_shift_ihdp.py
# ======================

#!/usr/bin/env python3
"""
pca_shift_ihdp.py

This script performs PCA on the IHDP covariates (columns x1 to x25 from the concatenated IHDP CSV),
then (a) induces a maximal covariate shift on the largest principal component (PC1) by flipping its values,
and (b) extracts a “latent confounder” from a smaller (but not the smallest) principal component (PC2).

The outputs are:
  - A new covariate dataset with the maximal shift applied (saved as processed_X_pca_shifted_max.csv),
    which retains the same header (x1,...,x25) as the original IHDP covariate file.
  - A latent confounder dataset (a single-column CSV, saved as processed_Z_pca.csv) with the PC2 values.

These files are created in the data/IHDP/ directory so that the IHDP data‐loader can use them for training/evaluation.
"""

import os
import argparse
import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

def flip_values(arr):
    """
    Given a 1D numpy array, return a flipped version:
    new_value = max + min - original.
    """
    min_val = np.min(arr)
    max_val = np.max(arr)
    return max_val + min_val - arr

def plot_pc_distribution(before, after, pc_index, plot_file):
    """
    Plot overlay histograms for a given principal component (pc_index)
    before and after shifting.
    """
    plt.figure(figsize=(8, 6))
    plt.hist(before, bins=50, alpha=0.5, density=True, label="Before Shift")
    plt.hist(after, bins=50, alpha=0.5, density=True, label="After Shift")
    plt.title(f"PC{pc_index+1} Distribution Before vs. After Shift")
    plt.xlabel(f"PC{pc_index+1} Score")
    plt.ylabel("Density")
    plt.legend()
    plt.tight_layout()
    plt.savefig(plot_file)
    plt.close()
    print(f"Plot saved to {plot_file}")

def main():
    parser = argparse.ArgumentParser(
        description="Perform PCA on IHDP covariates, induce maximal shift on PC1, and extract PC2 as latent confounder Z."
    )
    parser.add_argument("--input-file", type=str, default="data/IHDP/csv/concatenated_ihdp.csv",
                        help="Path to the IHDP concatenated CSV file (default: data/IHDP/csv/concatenated_ihdp.csv)")
    parser.add_argument("--n-components", type=int, default=25,
                        help="Number of PCA components to compute (default: 25, equal to number of covariates)")
    parser.add_argument("--plot-dir", type=str, default="pca_shift_plots",
                        help="Directory to save the PC before/after plots (default: pca_shift_plots)")
    args = parser.parse_args()

    # Load the IHDP concatenated CSV.
    if not os.path.exists(args.input_file):
        print(f"Error: Input file '{args.input_file}' does not exist.")
        return

    df_full = pd.read_csv(args.input_file)
    # Expect these columns:
    expected_cols = ["treatment", "y_factual", "y_cfactual", "mu0", "mu1"] + [f"x{i}" for i in range(1,26)]
    if not all(col in df_full.columns for col in expected_cols):
        raise ValueError("The IHDP CSV file does not contain the expected columns.")

    # Extract covariates (assumed to be x1,...,x25)
    covariate_cols = [f"x{i}" for i in range(1,26)]
    X_orig = df_full[covariate_cols].values  # shape (n_samples, 25)

    # Standardize the covariates.
    scaler = StandardScaler()
    X_std = scaler.fit_transform(X_orig)

    # Perform PCA.
    pca = PCA(n_components=args.n_components)
    PCs = pca.fit_transform(X_std)
    print("Explained variance ratios for computed components:")
    for i, ratio in enumerate(pca.explained_variance_ratio_):
        print(f"PC{i+1}: {ratio:.4f}")

    # ---- Dataset 1: Maximal shift on the largest PC (PC1) ----
    # Copy the PCA scores and flip the first principal component.
    PCs_shifted = np.copy(PCs)
    original_pc1 = PCs[:, 0]
    flipped_pc1 = flip_values(original_pc1)
    PCs_shifted[:, 0] = flipped_pc1

    # (Optional) Plot PC1 distribution before and after shifting.
    if not os.path.exists(args.plot_dir):
        os.makedirs(args.plot_dir, exist_ok=True)
    plot_file_pc1 = os.path.join(args.plot_dir, "PC1_before_after.png")
    plot_pc_distribution(original_pc1, flipped_pc1, 0, plot_file_pc1)

    # Reconstruct the shifted covariates.
    X_shifted_std = pca.inverse_transform(PCs_shifted)
    X_shifted = scaler.inverse_transform(X_shifted_std)
    # Create a DataFrame with the same covariate column names.
    df_X_shifted = pd.DataFrame(X_shifted, columns=covariate_cols)
    # Save the new covariate dataset.
    output_X_file = os.path.join("data", "IHDP", "processed_X_pca_shifted_max.csv")
    df_X_shifted.to_csv(output_X_file, index=False)
    print(f"New IHDP covariate dataset with maximal shift on PC1 saved to: {output_X_file}")

    # ---- Dataset 2: Encode a smaller-but-not-the-smallest PC (choose PC2) as latent confounder Z ----
    # Here we take PC2 (index 1) from the original PCA (from standardized data).
    latent_conf = PCs[:, 1]  # shape (n_samples,)
    # Optionally, plot PC2 distribution.
    plot_file_pc2 = os.path.join(args.plot_dir, "PC2_distribution.png")
    plt.figure(figsize=(8,6))
    plt.hist(latent_conf, bins=50, alpha=0.7, density=True)
    plt.title("PC2 Distribution (Used as Latent Confounder Z)")
    plt.xlabel("PC2 Score")
    plt.ylabel("Density")
    plt.tight_layout()
    plt.savefig(plot_file_pc2)
    plt.close()
    print(f"PC2 distribution plot saved to: {plot_file_pc2}")

    # Save the latent confounder as a one-column CSV.
    df_Z = pd.DataFrame(latent_conf, columns=["latent_conf"])
    output_Z_file = os.path.join("data", "IHDP", "processed_Z_pca.csv")
    df_Z.to_csv(output_Z_file, index=False)
    print(f"Latent confounder Z (from PC2) saved to: {output_Z_file}")

if __name__ == "__main__":
    main()


# ======================
# File: train_test.py
# ======================

#!/usr/bin/env python3
"""
train_test.py

This module implements training and evaluation pipelines for causal effect estimation
using both CEVAE (with latent confounder Z) and several baseline models.
In this updated version, the model is trained on the full training set.
For evaluation, we perform K-fold cross-validation on the test set to estimate performance.
"""

import numpy as np
import torch
import pyro
from xgboost import XGBRegressor
from sklearn.model_selection import KFold

from utils import evaluate_ite
from models import CEVAEWithZ

# --- Cross-validation functions on test set ---

def cross_validate_cevae_twins_test(
    X_test: torch.Tensor,
    t_test: torch.Tensor,
    y_test: torch.Tensor,
    Z_test: torch.Tensor,
    true_ite_test: np.ndarray,
    num_epochs: int,
    batch_size: int,
    learning_rate: float,
    learning_rate_decay: float,
    weight_decay: float,
    latent_dim: int,
    hidden_dim: int,
    num_layers: int,
    cv_folds: int = 5,
    seed: int = 0,
) -> dict:
    """
    Performs K-fold cross-validation for the CEVAE model on the test set of the Twins dataset.
    Splitting is done at the twin-pair level (using both twins per pair for evaluation).
    For each fold, the predicted ITE is computed as the difference between the estimated outcomes
    for twin1 and twin0.
    """
    total_samples = X_test.shape[0]
    N_pairs = total_samples // 2
    pair_indices = np.arange(N_pairs)
    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=seed)
    results = []

    for _, val_pairs in kf.split(pair_indices):
        # Get indices for each twin in the pair.
        val_twin0 = 2 * val_pairs
        val_twin1 = 2 * val_pairs + 1

        # Compute the true ITE for each pair.
        true_ite_val = (y_test[val_twin1] - y_test[val_twin0]).numpy()

        new_feature_dim = X_test.shape[1] + Z_test.shape[1]
        cevae = CEVAEWithZ(
            feature_dim=new_feature_dim,
            latent_dim=latent_dim,
            hidden_dim=hidden_dim,
            num_layers=num_layers,
            outcome_dist="normal",
            num_samples=10,
        )
        # Compute predicted outcomes for twin0 and twin1 separately.
        est_ite_twin0 = cevae.ite(X_test[val_twin0], Z_test[val_twin0]).detach().cpu().numpy()
        est_ite_twin1 = cevae.ite(X_test[val_twin1], Z_test[val_twin1]).detach().cpu().numpy()
        # Predicted ITE is the difference between twin1 and twin0.
        est_ite_val = est_ite_twin1 - est_ite_twin0

        ate, pehe, ate_abs_error = evaluate_ite(true_ite_val, est_ite_val)
        results.append((ate, pehe, ate_abs_error))

    avg_results = {
        "ATE_mean": np.mean([r[0] for r in results]),
        "ATE_std": np.std([r[0] for r in results]),
        "PEHE_mean": np.mean([r[1] for r in results]),
        "PEHE_std": np.std([r[1] for r in results]),
        "ATE_Abs_Error_mean": np.mean([r[2] for r in results]),
        "ATE_Abs_Error_std": np.std([r[2] for r in results]),
    }
    return avg_results

def cross_validate_cevae_ihdp_test(
    X_test: torch.Tensor,
    t_test: torch.Tensor,
    y_test: torch.Tensor,
    y_cf_test: torch.Tensor,
    Z_test: torch.Tensor,
    true_ite_test: np.ndarray,
    num_epochs: int,
    batch_size: int,
    learning_rate: float,
    learning_rate_decay: float,
    weight_decay: float,
    latent_dim: int,
    hidden_dim: int,
    num_layers: int,
    cv_folds: int = 5,
    seed: int = 0,
) -> dict:
    """
    Performs K-fold cross-validation for the CEVAE model on the test set of the IHDP dataset.
    For IHDP, true ITE is computed as:
        if t==1: y_test - y_cf_test else: y_cf_test - y_test.
    """
    total_samples = X_test.shape[0]
    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=seed)
    results = []

    for _, val_idx in kf.split(np.arange(total_samples)):
        X_val = X_test[val_idx]
        Z_val = Z_test[val_idx]
        t_val = t_test[val_idx]
        y_val = y_test[val_idx]
        y_cf_val = y_cf_test[val_idx]
        true_ite_val = np.where(t_val.numpy() == 1,
                                (y_val - y_cf_val).numpy(),
                                (y_cf_val - y_val).numpy())

        original_feature_dim = X_test.shape[1]
        new_feature_dim = original_feature_dim + Z_test.shape[1]
        cevae = CEVAEWithZ(
            feature_dim=new_feature_dim,
            outcome_dist="normal",
            latent_dim=latent_dim,
            hidden_dim=hidden_dim,
            num_layers=num_layers,
            num_samples=10,
        )
        est_ite_val = cevae.ite(X_val, Z_val).detach().cpu().numpy()
        ate, pehe, ate_abs_error = evaluate_ite(true_ite_val, est_ite_val)
        results.append((ate, pehe, ate_abs_error))

    avg_results = {
        "ATE_mean": np.mean([r[0] for r in results]),
        "ATE_std": np.std([r[0] for r in results]),
        "PEHE_mean": np.mean([r[1] for r in results]),
        "PEHE_std": np.std([r[1] for r in results]),
        "ATE_Abs_Error_mean": np.mean([r[2] for r in results]),
        "ATE_Abs_Error_std": np.std([r[2] for r in results]),
    }
    return avg_results

def train_and_evaluate(
    args,
    X: torch.Tensor,
    t: torch.Tensor,
    y: torch.Tensor,
    Z: torch.Tensor,
    X_train: torch.Tensor,
    t_train: torch.Tensor,
    y_train: torch.Tensor,
    Z_train: torch.Tensor,
    X_test: torch.Tensor,
    t_test: torch.Tensor,
    y_test: torch.Tensor,
    Z_test: torch.Tensor,
    true_ite_train: np.ndarray,
    true_ite_test: np.ndarray,
    XZ_train: np.ndarray,
    t_train_np: np.ndarray,
    y_train_np: np.ndarray,
    dataset: str,
    **kwargs,
) -> None:
    """
    Executes the training and evaluation pipeline.
    The model is trained on the full training set.
    Then, cross-validation is performed on the test set to obtain performance metrics.
    For IHDP, y_cf_test is also used to compute the true ITE.
    """
    if args.cuda:
        torch.set_default_device("cuda")
    pyro.set_rng_seed(args.seed)
    pyro.clear_param_store()

    # Train model on full training set.
    new_feature_dim = X.shape[1] + Z.shape[1] 
    if dataset == "ihdp":
        cevae = CEVAEWithZ(
            feature_dim=new_feature_dim,
            outcome_dist="normal",
            latent_dim=args.latent_dim,
            hidden_dim=args.hidden_dim,
            num_layers=args.num_layers,
            num_samples=10,
        )
    else:
        cevae = CEVAEWithZ(
            feature_dim=new_feature_dim,
            latent_dim=args.latent_dim,
            hidden_dim=args.hidden_dim,
            num_layers=args.num_layers,
            num_samples=10,
        )

    cevae.fit(
        X_train, t_train, y_train, z=Z_train,
        num_epochs=args.num_epochs,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        learning_rate_decay=args.learning_rate_decay,
        weight_decay=args.weight_decay,
    )

    # Evaluate using cross-validation on the test set.
    print("\nCross-validation on Test Set Evaluation:")
    if dataset == "twins":
        cv_results_cevae = cross_validate_cevae_twins_test(
            X_test, t_test, y_test, Z_test, true_ite_test,
            num_epochs=args.num_epochs,
            batch_size=args.batch_size,
            learning_rate=args.learning_rate,
            learning_rate_decay=args.learning_rate_decay,
            weight_decay=args.weight_decay,
            latent_dim=args.latent_dim,
            hidden_dim=args.hidden_dim,
            num_layers=args.num_layers,
            cv_folds=args.cv_folds,
            seed=args.seed,
        )
        print("CEVAE Test CV (Twins):", cv_results_cevae)
    else:  # ihdp
        cv_results_cevae = cross_validate_cevae_ihdp_test(
            X_test, t_test, y_test, kwargs["y_cf_test"], Z_test, true_ite_test,
            num_epochs=args.num_epochs,
            batch_size=args.batch_size,
            learning_rate=args.learning_rate,
            learning_rate_decay=args.learning_rate_decay,
            weight_decay=args.weight_decay,
            latent_dim=args.latent_dim,
            hidden_dim=args.hidden_dim,
            num_layers=args.num_layers,
            cv_folds=args.cv_folds,
            seed=args.seed,
        )
        print("CEVAE Test CV (IHDP):", cv_results_cevae)

    print("\nTrue causal effects on the test set:")
    print("True ATE (test):", np.mean(true_ite_test))
    print("True ITE (test) snippet:", true_ite_test[:10])


if __name__ == "__main__":
    # This file is meant to be imported and called by main.py
    pass


# ======================
# File: pca_shift_ihdp_modified.py
# ======================

#!/usr/bin/env python3
"""
pca_shift_ihdp_quantile.py

This script performs PCA on the modified IHDP covariates (24 covariates)
and applies a nonlinear, quantile-based shift on the top components.
It then reconstructs the shifted covariates for training.

Rationale:
  - A purely linear flip or scale is largely undone by standard scaling.
  - This quantile-based shift warps the distribution in a continuous, nonlinear way,
    so that the transformation remains detectable even after inverse whitening.
  - The new transformation uses a piecewise power function that “bends” the
    empirical CDF more extremely (with gamma > 1, the mid-range values are pushed
    further away from the center), making the covariate shift even more pronounced.
"""

import os
import argparse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

def extreme_quantile_shift(pc_values, gamma=2.0):
    """
    Apply an extreme nonlinear quantile-based shift to the PC values.
    
    For each value in pc_values, this function:
      1. Computes the empirical CDF (quantile) and rescales it to [0, 1].
      2. Applies a piecewise power transformation:
           - For q < 0.5:  f(q) = q^(1/gamma)
           - For q >= 0.5: f(q) = 1 - (1-q)^(1/gamma)
         This pushes mid-range values farther away from 0.5.
      3. Computes the shift as (f(q) - q)*data_range and adds it to the original value.
      4. Optionally adds small random noise to break ties.
    
    Parameters:
      pc_values : np.array, the PC scores for one dimension.
      gamma     : float, controls the magnitude of the nonlinearity. 
                       When gamma=1, f(q)=q (i.e. no shift). For gamma>1, the transformation
                       becomes more extreme.
                       
    Returns:
      np.array: The shifted PC values.
    """
    arr = pc_values.copy()
    n = len(arr)
    # Compute empirical CDF: rank each value uniformly between 0 and 1.
    sorted_indices = np.argsort(arr)
    ranks = np.empty_like(sorted_indices, dtype=float)
    ranks[sorted_indices] = np.linspace(0, 1, num=n)
    
    data_range = arr.max() - arr.min()
    
    # Apply piecewise power transformation on the quantiles:
    f = np.empty_like(ranks)
    lower_mask = ranks < 0.5
    upper_mask = ~lower_mask
    # For values below the median:
    f[lower_mask] = np.power(ranks[lower_mask], 1.0/gamma)
    # For values at or above the median:
    f[upper_mask] = 1 - np.power(1 - ranks[upper_mask], 1.0/gamma)
    
    # Compute shift: the difference between the transformed and original quantiles
    shift_amount = (f - ranks) * data_range
    
    # Add shift and optional small noise
    arr_shifted = arr + shift_amount
    noise_scale = 0.05 * (data_range + 1e-8)
    arr_shifted += np.random.normal(loc=0, scale=noise_scale, size=arr.shape)
    
    return arr_shifted

def plot_pc_distribution(before, after, pc_index, plot_file):
    """
    Plot overlay histograms for a given principal component (pc_index)
    before and after shifting.
    """
    plt.figure(figsize=(8, 6))
    plt.hist(before, bins=50, alpha=0.5, density=True, label="Before Shift")
    plt.hist(after, bins=50, alpha=0.5, density=True, label="After Shift")
    plt.title(f"PC{pc_index+1} Distribution Before vs. After Shift")
    plt.xlabel(f"PC{pc_index+1} Score")
    plt.ylabel("Density")
    plt.legend()
    plt.tight_layout()
    plt.savefig(plot_file)
    plt.close()
    print(f"Plot saved to: {plot_file}")

def main():
    parser = argparse.ArgumentParser(
        description="Perform PCA on modified IHDP covariates (24 columns) and apply an extreme nonlinear quantile shift on the top PCs."
    )
    parser.add_argument("--input-file", type=str, default="data/IHDP/processed_X_ihdp_modified.csv",
                        help="Modified IHDP covariate file (24 covariates).")
    parser.add_argument("--output-file", type=str, default="data/IHDP/processed_X_pca_shifted.csv",
                        help="Output file for the PCA-shifted IHDP covariates.")
    parser.add_argument("--n-components", type=int, default=24,
                        help="Number of PCA components to compute (default: 24)")
    parser.add_argument("--plot-dir", type=str, default="pca_shift_plots",
                        help="Directory to save the PC distribution plots.")
    parser.add_argument("--gamma", type=float, default=2.0,
                        help="Tuning parameter for the magnitude of the extreme quantile shift (default: 2.0)")
    args = parser.parse_args()

    if not os.path.exists(args.input_file):
        print(f"Error: Input file {args.input_file} does not exist.")
        return

    df = pd.read_csv(args.input_file)
    covariate_cols = df.columns.tolist()  # Expecting 24 covariates.
    X = df.values  # shape: (n_samples, 24)

    # Standardize the covariates.
    scaler = StandardScaler()
    X_std = scaler.fit_transform(X)

    # Perform PCA.
    pca = PCA(n_components=args.n_components)
    PCs = pca.fit_transform(X_std)

    print("Explained Variance Ratios:")
    for i, ratio in enumerate(pca.explained_variance_ratio_):
        suffix = " (top PCs)" if i < 5 else ""
        print(f"  PC{i+1}{suffix}: {ratio:.2%}")

    # Copy PCs to be shifted.
    PCs_shifted = PCs.copy()
    # We apply the extreme shift on the top 5 components.
    top_k = 24
    if PCs.shape[1] < top_k:
        raise ValueError(f"Found {PCs.shape[1]} components, need at least {top_k}.")

    for i in range(top_k):
        original_pc = PCs[:, i]
        shifted_pc = extreme_quantile_shift(original_pc, gamma=args.gamma)
        PCs_shifted[:, i] = shifted_pc

    # Plot distributions for the top 5 PCs.
    if not os.path.exists(args.plot_dir):
        os.makedirs(args.plot_dir, exist_ok=True)
    for i in range(top_k):
        plot_file = os.path.join(args.plot_dir, f"PC{i+1}_before_after.png")
        plot_pc_distribution(PCs[:, i], PCs_shifted[:, i], i, plot_file)

    # Inverse transform back to the original feature space.
    X_shifted_std = pca.inverse_transform(PCs_shifted)
    X_shifted = scaler.inverse_transform(X_shifted_std)

    df_shifted = pd.DataFrame(X_shifted, columns=covariate_cols)
    df_shifted.to_csv(args.output_file, index=False)
    print(f"\nPCA-shifted IHDP covariate dataset saved to: {args.output_file}")
    print("Top 5 PCs were transformed via an extreme nonlinear quantile-based shift to induce a robust covariate shift.")

if __name__ == "__main__":
    main()


# ======================
# File: utils.py
# ======================

import numpy as np

from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.metrics import mean_squared_error
from xgboost import XGBRegressor

from econml.dml import DML
from econml.metalearners import XLearner
from econml.sklearn_extensions.linear_model import StatsModelsLinearRegression

from sklearn.model_selection import KFold


##############################################################################
# 3-fold CV wrappers for every model (for causal baselines)
##############################################################################

def estimate_ate_ipw_cv(XZ, t, y, cv=3):
    """
    Estimate ATE via IPW using 3-fold cross-validation.
    Since IPW naturally estimates the overall ATE (not individual treatment effects),
    we perform CV: in each fold, the propensity model is trained on the training set,
    then ATE is computed on the validation set. The final ATE is the weighted average.
    """
    kf = KFold(n_splits=cv, shuffle=True, random_state=0)
    ate_folds = []
    fold_sizes = []
    for train_index, val_index in kf.split(XZ):
        XZ_train, XZ_val = XZ[train_index], XZ[val_index]
        t_train, t_val = t[train_index], t[val_index]
        y_val = y[val_index]
        scaler = StandardScaler()
        XZ_train_scaled = scaler.fit_transform(XZ_train)
        XZ_val_scaled = scaler.transform(XZ_val)
        lr = LogisticRegression(max_iter=10000)
        lr.fit(XZ_train_scaled, t_train)
        p_val = lr.predict_proba(XZ_val_scaled)[:, 1]
        p_val = np.clip(p_val, 1e-5, 1 - 1e-5)
        ate_fold = np.mean(y_val[t_val == 1] / p_val[t_val == 1]) - np.mean(y_val[t_val == 0] / (1 - p_val[t_val == 0]))
        ate_folds.append(ate_fold)
        fold_sizes.append(len(val_index))
    total = np.sum(fold_sizes)
    ate_cv = np.sum(np.array(ate_folds) * np.array(fold_sizes)) / total
    return ate_cv


def estimate_ite_dml_cv(XZ, t, y, cv=3):
    """
    Estimate ITE via DML using 3-fold cross-validation.
    For each fold, a DML instance is trained on the training data and then used to
    predict individual treatment effects on the validation fold.
    The ITE predictions are then aggregated (in original order) and returned.
    """
    kf = KFold(n_splits=cv, shuffle=True, random_state=0)
    ite_pred = np.empty(XZ.shape[0])
    for train_index, val_index in kf.split(XZ):
        XZ_train, XZ_val = XZ[train_index], XZ[val_index]
        t_train, t_val = t[train_index], t[val_index]
        y_train = y[train_index]
        dml = DML(
            model_y=RandomForestRegressor(random_state=0),
            model_t=RandomForestClassifier(random_state=0),
            model_final=StatsModelsLinearRegression(fit_intercept=False),
            discrete_treatment=True
        )
        dml.fit(y_train, t_train, X=XZ_train)
        ite_pred[val_index] = dml.effect(XZ_val, T0=0, T1=1)
    return ite_pred


def estimate_ite_xlearner_cv(XZ, t, y, cv=3):
    """
    Estimate ITE via X-Learner using 3-fold cross-validation.
    """
    kf = KFold(n_splits=cv, shuffle=True, random_state=0)
    ite_pred = np.empty(XZ.shape[0])
    for train_index, val_index in kf.split(XZ):
        XZ_train, XZ_val = XZ[train_index], XZ[val_index]
        t_train, t_val = t[train_index], t[val_index]
        y_train = y[train_index]
        base_learner = RandomForestRegressor(random_state=0)
        xlearner = XLearner(models=base_learner)
        xlearner.fit(y_train, t_train, X=XZ_train)
        ite_pred[val_index] = xlearner.effect(XZ_val)
    return ite_pred


##############################################################################
# Traditional (non-causal) baseline CV for SVM, KNN, and XGBoost
##############################################################################

def estimate_ite_traditional_cv(model_class, X, t, y, cv=3, **model_kwargs):
    """
    Estimate ITE using traditional k-fold cross validation.
    In each fold, a regression model is trained on the entire training data,
    where the features are concatenated with the treatment indicator.
    For each validation sample, two predictions are made:
      - One with treatment set to 1.
      - One with treatment set to 0.
    The difference of these predictions is taken as the estimated ITE.
    """
    kf = KFold(n_splits=cv, shuffle=True, random_state=0)
    ite_pred = np.empty(X.shape[0])
    for train_index, val_index in kf.split(X):
        X_train, X_val = X[train_index], X[val_index]
        t_train, t_val = t[train_index], t[val_index]
        y_train = y[train_index]
        # Train on training data: concatenate treatment indicator.
        X_train_full = np.concatenate([X_train, t_train.reshape(-1, 1)], axis=1)
        model = model_class(**model_kwargs)
        model.fit(X_train_full, y_train)
        # For validation, prepare two versions: one with treatment=1 and one with treatment=0.
        X_val_t1 = np.concatenate([X_val, np.ones((X_val.shape[0], 1))], axis=1)
        X_val_t0 = np.concatenate([X_val, np.zeros((X_val.shape[0], 1))], axis=1)
        y1_pred = model.predict(X_val_t1)
        y0_pred = model.predict(X_val_t0)
        ite_pred[val_index] = y1_pred - y0_pred
    return ite_pred


def estimate_ite_svm_cv(X, t, y, cv=3, **model_kwargs):
    """
    ITE estimation using Support Vector Regression with traditional k-fold CV.
    """
    return estimate_ite_traditional_cv(SVR, X, t, y, cv=cv, **model_kwargs)


def estimate_ite_knn_cv(X, t, y, cv=3, **model_kwargs):
    """
    ITE estimation using K-Nearest Neighbors Regressor with traditional k-fold CV.
    """
    return estimate_ite_traditional_cv(KNeighborsRegressor, X, t, y, cv=cv, **model_kwargs)


def estimate_ite_xgb_cv(X, t, y, cv=3, **model_kwargs):
    """
    ITE estimation using XGBoost Regressor with traditional k-fold CV.
    """
    return estimate_ite_traditional_cv(XGBRegressor, X, t, y, cv=cv, **model_kwargs)


##############################################################################
# Evaluate ITE predictions
##############################################################################

def evaluate_ite(y_true, ite_est):
    """
    Model evaluation.
    Computes:
      - ATE estimated as the mean of ite_est.
      - PEHE (precision in estimation of heterogeneous effect) as RMSE.
      - Absolute error in ATE.
    
    For Twins data, if the predicted ITE is computed per individual (length = 2 * len(y_true)),
    we aggregate the predictions per twin-pair by computing:
      aggregated_ite = ite_est[twin1] - ite_est[twin0]
    """
    if len(ite_est) == 2 * len(y_true):
        half = len(y_true)
        ite_est = ite_est[half:] - ite_est[:half]
    ate_est = np.mean(ite_est)
    ate_true = np.mean(y_true)
    ate_abs_error = np.abs(ate_est - ate_true)
    pehe = np.sqrt(mean_squared_error(y_true, ite_est))
    return ate_est, pehe, ate_abs_error


##############################################################################
# Direct model estimation without CV (for reference)
##############################################################################

def estimate_ite_direct(model_class, X_train_pairs, y_train_ite, X_val_pairs, **model_kwargs):
    """
    Noncausal fitting and ITE estimation.
    """
    model = model_class(**model_kwargs)
    model.fit(X_train_pairs, y_train_ite)
    ite_est_val = model.predict(X_val_pairs)
    return ite_est_val


##############################################################################
# T-learner based ITE estimation with 3-fold CV (for causal baselines)
##############################################################################

def estimate_ite_tlearner_cv(model_class, X, t, y, cv=3, **model_kwargs):
    """
    Performs 3-fold cross-validation using a T-learner approach.
    In each fold, the data (X, t, y) are split into training and validation.
    Two separate models are fit:
       - One on the treated observations (t==1) of the training fold.
       - One on the control observations (t==0) of the training fold.
    For each validation fold, potential outcomes are predicted using these two models and
    the estimated ITE is computed as: prediction for treated minus prediction for control.
    The predictions are then aggregated (in the original order) and returned.
    """
    kf = KFold(n_splits=cv, shuffle=True, random_state=0)
    ite_pred = np.empty(X.shape[0])
    for train_index, val_index in kf.split(X):
        X_train, X_val = X[train_index], X[val_index]
        t_train, t_val = t[train_index], t[val_index]
        y_train = y[train_index]
        treated_idx = t_train == 1
        control_idx = t_train == 0
        if np.sum(treated_idx) == 0 or np.sum(control_idx) == 0:
            ite_pred[val_index] = np.mean(y_train[t_train == 1]) - np.mean(y_train[t_train == 0])
            continue
        model_treated = model_class(**model_kwargs)
        model_control = model_class(**model_kwargs)
        model_treated.fit(X_train[treated_idx], y_train[treated_idx])
        model_control.fit(X_train[control_idx], y_train[control_idx])
        y1_pred = model_treated.predict(X_val)
        y0_pred = model_control.predict(X_val)
        ite_pred[val_index] = y1_pred - y0_pred
    return ite_pred


def estimate_ite_interaction_cv(X, t, y, cv=3, **model_kwargs):
    """
    ITE estimation using Interacted Linear Regression (T-learner on interaction features)
    with 3-fold CV. Interaction features are generated using PolynomialFeatures.
    """
    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
    X_inter = poly.fit_transform(X)
    return estimate_ite_tlearner_cv(LinearRegression, X_inter, t, y, cv=cv, **model_kwargs)


# ======================
# File: main.py
# ======================

#!/usr/bin/env python3
import argparse
import logging
import torch
import pandas as pd
import numpy as np
import os
import io
from contextlib import redirect_stdout

# data-loading
from data import load_ihdp_data, prepare_train_test_split_ihdp
from data import load_twins_data, prepare_train_test_split

# training/evaluation
from train_test import train_and_evaluate

def comprehensive_evaluation(args):
    # Define the sweep parameters.
    datasets = ["twins", "ihdp"]
    shift_options = [False, True]  # non-shifted and shifted
    p_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]

    # Loop over each dataset.
    for dataset in datasets:
        log_filename = f"evaluation_{dataset}.txt"
        with open(log_filename, "w") as log_file:
            log_file.write(f"=== Comprehensive Evaluation for dataset: {dataset} ===\n")
            # Loop over shifted vs. non-shifted.
            for train_shifted in shift_options:
                log_file.write(f"\n--- Train shifted = {train_shifted} ---\n")
                # Loop over flipping probabilities.
                for p in p_values:
                    log_file.write(f"\n*** Experiment: flipping probability p = {p} ***\n")
                    # Load data and override Z based on p.
                    if dataset == "ihdp":
                        # Load IHDP data (X_input, t, y, y_cf, Z) with given train_shifted flag.
                        X_input, t, y, y_cf, Z = load_ihdp_data(train_shifted=train_shifted)
                        # Override latent confounder Z by loading the file for current p.
                        z_file = f"data/IHDP/processed_Z_ihdp_p{p}.csv"
                        try:
                            Z_df = pd.read_csv(z_file)
                            Z = torch.tensor(Z_df.values, dtype=torch.float)
                            log_file.write(f"Loaded IHDP Z from {z_file}\n")
                        except Exception as e:
                            log_file.write(f"Error loading IHDP Z from {z_file}: {e}\n")
                        (X_train, t_train, y_train, y_cf_train, Z_train,
                         X_test, t_test, y_test, y_cf_test, Z_test,
                         true_ite_train, true_ite_test,
                         XZ_train, t_train_np, y_train_np,
                         train_idx, test_idx) = prepare_train_test_split_ihdp(
                            X_input, t, y, y_cf, Z,
                            test_size=args.test_size,
                            seed=args.seed
                        )
                        extra_args = {"y_cf_test": y_cf_test}
                        data_for_training = X_input
                    else:  # twins
                        # Load Twins data with train_shifted flag.
                        X, t, y, Z = load_twins_data(train_shifted=train_shifted)
                        # Override latent confounder Z by loading file for current p.
                        z_file = f"data/TWINS/processed_z_p{p}.csv"
                        try:
                            Z_df = pd.read_csv(z_file)
                            Z = torch.tensor(Z_df.values, dtype=torch.float)
                            log_file.write(f"Loaded Twins Z from {z_file}\n")
                        except Exception as e:
                            log_file.write(f"Error loading Twins Z from {z_file}: {e}\n")
                        (X_train, t_train, y_train, Z_train,
                         X_test, t_test, y_test, Z_test,
                         true_ite_train, true_ite_test,
                         XZ_train, t_train_np, y_train_np,
                         train_twin0, train_twin1,
                         test_twin0, test_twin1) = prepare_train_test_split(
                            X, t, y, Z,
                            num_data=args.num_data,
                            test_size=args.test_size,
                            seed=args.seed
                        )
                        extra_args = {
                            "train_twin0": train_twin0,
                            "train_twin1": train_twin1,
                            "test_twin0": test_twin0,
                            "test_twin1": test_twin1
                        }
                        data_for_training = X
                    # Capture output of evaluation.
                    buffer = io.StringIO()
                    with redirect_stdout(buffer):
                        # Train and evaluate CEVAE.
                        if not args.skip_cevae:
                            train_and_evaluate(
                                args,
                                data_for_training, t, y, Z,
                                X_train, t_train, y_train, Z_train,
                                X_test, t_test, y_test, Z_test,
                                true_ite_train, true_ite_test,
                                XZ_train, t_train_np, y_train_np,
                                dataset=dataset,
                                **extra_args
                            )
                        else:
                            print("Skipping CEVAE training and evaluation as requested (--skip-cevae).")
                        # Baseline evaluations.
                        if args.skip_cevae or not args.only_cevae:
                            print("\nRunning baseline evaluations using utility models via 3-fold CV...")
                            from utils import (
                                estimate_ate_ipw_cv,
                                estimate_ite_dml_cv,
                                estimate_ite_xlearner_cv,
                                estimate_ite_svm_cv,
                                estimate_ite_knn_cv,
                                estimate_ite_interaction_cv,
                                estimate_ite_xgb_cv,
                                evaluate_ite,
                            )
                            if dataset == "twins":
                                ate_ipw_cv = estimate_ate_ipw_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                print(f"IPW CV (ATE) for Twins: {ate_ipw_cv:.4f}")
                                dml_cv = estimate_ite_dml_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                dml_cv = np.array(dml_cv).reshape(-1)
                                ate_dml, pehe_dml, ate_abs_dml = evaluate_ite(true_ite_train, dml_cv)
                                print(f"DML CV (Twins): ATE={ate_dml:.4f}, PEHE={pehe_dml:.4f}, ATE_Abs_Error={ate_abs_dml:.4f}")
                                xl_cv = estimate_ite_xlearner_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                xl_cv = np.array(xl_cv).reshape(-1)
                                ate_xl, pehe_xl, ate_abs_xl = evaluate_ite(true_ite_train, xl_cv)
                                print(f"X-Learner CV (Twins): ATE={ate_xl:.4f}, PEHE={pehe_xl:.4f}, ATE_Abs_Error={ate_abs_xl:.4f}")
                                svm_cv = estimate_ite_svm_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                svm_cv = np.array(svm_cv).reshape(-1)
                                ate_svm, pehe_svm, abs_svm = evaluate_ite(true_ite_train, svm_cv)
                                print(f"SVM CV (Twins): ATE={ate_svm:.4f}, PEHE={pehe_svm:.4f}, ATE_Abs_Error={abs_svm:.4f}")
                                knn_cv = estimate_ite_knn_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                knn_cv = np.array(knn_cv).reshape(-1)
                                ate_knn, pehe_knn, abs_knn = evaluate_ite(true_ite_train, knn_cv)
                                print(f"KNN CV (Twins): ATE={ate_knn:.4f}, PEHE={pehe_knn:.4f}, ATE_Abs_Error={abs_knn:.4f}")
                                ilr_cv = estimate_ite_interaction_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                ilr_cv = np.array(ilr_cv).reshape(-1)
                                ate_ilr, pehe_ilr, abs_ilr = evaluate_ite(true_ite_train, ilr_cv)
                                print(f"Interacted LR CV (Twins): ATE={ate_ilr:.4f}, PEHE={pehe_ilr:.4f}, ATE_Abs_Error={abs_ilr:.4f}")
                                xgb_cv = estimate_ite_xgb_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                xgb_cv = np.array(xgb_cv).reshape(-1)
                                ate_xgb, pehe_xgb, abs_xgb = evaluate_ite(true_ite_train, xgb_cv)
                                print(f"XGBoost CV (Twins): ATE={ate_xgb:.4f}, PEHE={pehe_xgb:.4f}, ATE_Abs_Error={abs_xgb:.4f}")
                            else:
                                ate_ipw_cv = estimate_ate_ipw_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                print(f"IPW CV (ATE) for IHDP: {ate_ipw_cv:.4f}")
                                dml_cv = estimate_ite_dml_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                dml_cv = np.array(dml_cv).reshape(-1)
                                ate_dml, pehe_dml, ate_abs_dml = evaluate_ite(true_ite_train, dml_cv)
                                print(f"DML CV (IHDP): ATE={ate_dml:.4f}, PEHE={pehe_dml:.4f}, ATE_Abs_Error={ate_abs_dml:.4f}")
                                xl_cv = estimate_ite_xlearner_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                xl_cv = np.array(xl_cv).reshape(-1)
                                ate_xl, pehe_xl, abs_xl = evaluate_ite(true_ite_train, xl_cv)
                                print(f"X-Learner CV (IHDP): ATE={ate_xl:.4f}, PEHE={pehe_xl:.4f}, ATE_Abs_Error={abs_xl:.4f}")
                                svm_cv = estimate_ite_svm_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                svm_cv = np.array(svm_cv).reshape(-1)
                                ate_svm, pehe_svm, abs_svm = evaluate_ite(true_ite_train, svm_cv)
                                print(f"SVM CV (IHDP): ATE={ate_svm:.4f}, PEHE={pehe_svm:.4f}, ATE_Abs_Error={abs_svm:.4f}")
                                knn_cv = estimate_ite_knn_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                knn_cv = np.array(knn_cv).reshape(-1)
                                ate_knn, pehe_knn, abs_knn = evaluate_ite(true_ite_train, knn_cv)
                                print(f"KNN CV (IHDP): ATE={ate_knn:.4f}, PEHE={pehe_knn:.4f}, ATE_Abs_Error={abs_knn:.4f}")
                                ilr_cv = estimate_ite_interaction_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                ilr_cv = np.array(ilr_cv).reshape(-1)
                                ate_ilr, pehe_ilr, abs_ilr = evaluate_ite(true_ite_train, ilr_cv)
                                print(f"Interacted LR CV (IHDP): ATE={ate_ilr:.4f}, PEHE={pehe_ilr:.4f}, ATE_Abs_Error={abs_ilr:.4f}")
                                xgb_cv = estimate_ite_xgb_cv(XZ_train, t_train_np, y_train_np, cv=args.cv_folds)
                                xgb_cv = np.array(xgb_cv).reshape(-1)
                                ate_xgb, pehe_xgb, abs_xgb = evaluate_ite(true_ite_train, xgb_cv)
                                print(f"XGBoost CV (IHDP): ATE={ate_xgb:.4f}, PEHE={pehe_xgb:.4f}, ATE_Abs_Error={abs_xgb:.4f}")
                    # Write the captured output to the log file.
                    experiment_output = buffer.getvalue()
                    log_file.write(experiment_output)
    print("Comprehensive evaluation completed.")

def main():
    parser = argparse.ArgumentParser(
        description="Comprehensive evaluation of datasets (Twins and IHDP) with shifted and non-shifted covariates, across various flipping probabilities."
    )
    # Base hyperparameters.
    parser.add_argument("--test-size", default=0.2, type=float)
    parser.add_argument("--cv-folds", default=3, type=int)
    parser.add_argument("--num-data", type=int, default=23968)  # Relevant for Twins.
    parser.add_argument("--feature-dim", type=int)
    parser.add_argument("--num-epochs", type=int)
    parser.add_argument("--latent-dim", type=int)
    parser.add_argument("--hidden-dim", type=int)
    parser.add_argument("--num-layers", type=int)
    parser.add_argument("--batch-size", type=int)
    parser.add_argument("--learning-rate", type=float)
    parser.add_argument("--learning-rate-decay", type=float)
    parser.add_argument("--weight-decay", type=float)
    parser.add_argument("--seed", default=23, type=int)
    parser.add_argument("--jit", action="store_true")
    parser.add_argument("--cuda", action="store_true")
    parser.add_argument("--only-cevae", action="store_true", default=False)
    parser.add_argument("--skip-cevae", action="store_true", default=False)
    # Set default hyperparameters for each dataset.
    parser.add_argument("--default-twins", action="store_true", help="Use Twins default hyperparameters")
    parser.add_argument("--default-ihdp", action="store_true", help="Use IHDP default hyperparameters")
    args = parser.parse_args()

    # For simplicity, if feature_dim not set, use defaults per dataset later.
    logging.getLogger("pyro").setLevel(logging.DEBUG)
    if logging.getLogger("pyro").handlers:
        logging.getLogger("pyro").handlers[0].setLevel(logging.DEBUG)

    comprehensive_evaluation(args)

if __name__ == "__main__":
    main()


# ======================
# File: visual_cevae.py
# ======================

"""
visual_cevae.py

This module implements a multi-panel interactive dashboard for the CEVAE.
A fixed DAG representing the CEVAE architecture (nodes: X, T, Y, Z with edges: Z→X, Z→T, Z→Y, T→Y)
is shown alongside time-series plots tracking key parameter statistics (e.g., average absolute weights)
and performance metrics (ELBO loss) over training epochs. In addition, an animated t-SNE visualization of
the latent variable distributions is displayed to illustrate convergence and representation shifts.
The dashboard is updated efficiently with non-blocking rendering, and the final dashboard is saved as an image.
"""

import matplotlib.pyplot as plt
import networkx as nx
import torch
import pyro
from pyro import poutine
from pyro.contrib.cevae import CEVAE, Model, Guide
import numpy as np
from matplotlib.colors import LinearSegmentedColormap
from sklearn.manifold import TSNE
from torch.utils.data import DataLoader, TensorDataset
from pyro.optim import ClippedAdam
from pyro.infer import SVI
from pyro.contrib.cevae import TraceCausalEffect_ELBO

# --- Dashboard Initialization Utilities ---

def _init_dashboard():
    """
    Create a dashboard figure with 4 subplots arranged in a 2x2 grid:
        - Top-left: Static DAG (architecture)
        - Top-right: Parameter metrics time-series
        - Bottom-left: Performance (ELBO loss) time-series
        - Bottom-right: t-SNE of latent representations
    Returns a dictionary of axes and the figure.
    """
    fig, axs = plt.subplots(2, 2, figsize=(12, 8))
    dashboard = {
        "dag": axs[0, 0],
        "param": axs[0, 1],
        "perf": axs[1, 0],
        "tsne": axs[1, 1],
        "fig": fig
    }
    plt.ion()  # Enable interactive mode.
    return dashboard

def _init_static_dag():
    """
    Initialize the static DAG for the CEVAE architecture.
    Returns (G, pos) for nodes: X, T, Y, Z with edges: Z→X, Z→T, Z→Y, T→Y.
    """
    G = nx.DiGraph()
    nodes = ["X", "T", "Y", "Z"]
    G.add_nodes_from(nodes)
    edges = [("Z", "X"), ("Z", "T"), ("Z", "Y"), ("T", "Y")]
    G.add_edges_from(edges)
    pos = nx.spring_layout(G, seed=42)
    return G, pos

def _draw_dag(ax, G, pos, norm_metrics):
    """
    Draw the static DAG on the provided axis, updating node colors based on normalized metrics.
    Colors interpolate between purple (#800080, low) and deep blue (#00008B, high).
    """
    from matplotlib.colors import LinearSegmentedColormap
    cmap = LinearSegmentedColormap.from_list("custom_cmap", ["#800080", "#00008B"])
    node_colors = [cmap(norm_metrics.get(node, 0.5)) for node in G.nodes()]
    ax.clear()
    nx.draw(G, pos, ax=ax, with_labels=True, node_color=node_colors,
            arrows=True, arrowstyle='->', arrowsize=20)
    ax.set_title("CEVAE Architecture")
    
def _update_time_series(ax, epochs, series, title, ylabel):
    """
    Update a time-series plot on the given axis.
    epochs: list of epoch numbers.
    series: dict mapping series label to list of values.
    """
    ax.clear()
    for label, values in series.items():
        ax.plot(epochs, values, label=label)
    ax.set_title(title)
    ax.set_xlabel("Epoch")
    ax.set_ylabel(ylabel)
    ax.legend()

def _update_tsne(ax, tsne_emb, title="Latent t-SNE"):
    """
    Update the t-SNE scatter plot on the given axis.
    tsne_emb: array of shape (n_samples, 2)
    """
    ax.clear()
    ax.scatter(tsne_emb[:, 0], tsne_emb[:, 1], c='green', alpha=0.7)
    ax.set_title(title)
    ax.set_xlabel("Dim 1")
    ax.set_ylabel("Dim 2")
    plt.draw()
    plt.pause(0.001)

# --- Custom Visual Model and Guide ---

class VisualModel(Model):
    def forward(self, x, t=None, y=None, size=None):
        if size is None:
            size = x.size(0)
        with pyro.plate("data", size, subsample=x):
            z = pyro.sample("z", self.z_dist())
            x_val = pyro.sample("x", self.x_dist(z), obs=x)
            t_val = pyro.sample("t", self.t_dist(z), obs=t)
            y_val = pyro.sample("y", self.y_dist(t, z), obs=y)
        return y_val

class VisualGuide(Guide):
    def forward(self, x, t=None, y=None, size=None):
        if size is None:
            size = x.size(0)
        with pyro.plate("data", size, subsample=x):
            t = pyro.sample("t", self.t_dist(x), obs=t, infer={"is_auxiliary": True})
            y = pyro.sample("y", self.y_dist(t, x), obs=y, infer={"is_auxiliary": True})
            pyro.sample("z", self.z_dist(y, t, x))
        return None

# --- Visual CEVAE with Interactive Dashboard and Training History ---

class VisualCEVAE(CEVAE):
    """
    A version of CEVAE that displays an interactive, multi-panel dashboard.
    The dashboard includes:
      - A fixed DAG of the model architecture.
      - Time-series plots of parameter metrics (average absolute weights) for nodes.
      - A time-series plot of the ELBO loss.
      - A dynamic t-SNE visualization of latent variable representations.
    The dashboard is updated every vis_update_interval epochs and saved as "final_dashboard.png".

    Now also includes debug logging to show a sample of X each epoch.
    """
    def __init__(self, feature_dim, outcome_dist="bernoulli",
                 latent_dim=20, hidden_dim=200, num_layers=3, num_samples=100):
        config = dict(feature_dim=feature_dim,
                      latent_dim=latent_dim,
                      hidden_dim=hidden_dim,
                      num_layers=num_layers,
                      num_samples=num_samples)
        config["outcome_dist"] = outcome_dist
        self.feature_dim = feature_dim
        self.num_samples = num_samples
        super().__init__(feature_dim, outcome_dist, latent_dim, hidden_dim, num_layers, num_samples)
        self.model = VisualModel(config)
        self.guide = VisualGuide(config)

        # Define a default whitening function to be used in ite even if fit was not called.
        self.whiten = lambda data: (data - data.mean(0)) / (data.std(0) + 1e-6)

        # Initialize dashboard and static DAG.
        self.dashboard = _init_dashboard()
        self.G, self.pos = _init_static_dag()

        # Initialize history containers.
        self.history = {
            "epoch": [],
            "param": {"X": [], "T": [], "Y": [], "Z": []},
            "perf": [],  # ELBO loss per epoch.
            "tsne": []   # Store latent representations for t-SNE.
        }
        # Fix a validation batch for t-SNE visualization.
        self._fixed_data = None

    def compute_node_metrics(self):
        """
        Compute average absolute weight values for nodes X, T, and Y.
        For Z, we just set a fixed constant for display.
        """
        metrics = {}
        norm_x = 0.0
        count = 0
        if hasattr(self.model, 'x_nn'):
            for param in self.model.x_nn.fc.parameters():
                norm_x += param.abs().mean().item()
                count += 1
        metrics["X"] = norm_x / count if count > 0 else 0.5

        norm_t = 0.0
        count = 0
        if hasattr(self.model, 't_nn'):
            for param in self.model.t_nn.fc.parameters():
                norm_t += param.abs().mean().item()
                count += 1
        metrics["T"] = norm_t / count if count > 0 else 0.5

        norm_y0 = 0.0
        count0 = 0
        if hasattr(self.model, 'y0_nn'):
            for param in self.model.y0_nn.fc.parameters():
                norm_y0 += param.abs().mean().item()
                count0 += 1
        norm_y1 = 0.0
        count1 = 0
        if hasattr(self.model, 'y1_nn'):
            for param in self.model.y1_nn.fc.parameters():
                norm_y1 += param.abs().mean().item()
                count1 += 1
        avg_y0 = (norm_y0 / count0 if count0 else 0.5)
        avg_y1 = (norm_y1 / count1 if count1 else 0.5)
        metrics["Y"] = (avg_y0 + avg_y1) / 2

        metrics["Z"] = 1.0
        return metrics

    def _extract_latent(self, x, t, y):
        """
        Extract latent variable "z" from the guide using poutine.trace.
        Returns a tensor of shape (n_samples, latent_dim).
        """
        with poutine.trace() as tracer:
            self.guide(x, t, y)
        for name, site in tracer.trace.nodes.items():
            if name == "z":
                return site["value"]
        return None

    def _save_final_dashboard(self, filename):
        self.dashboard["fig"].savefig(filename)

    def fit(self, x, t, y, num_epochs=100, batch_size=100,
            learning_rate=1e-3, learning_rate_decay=0.1, weight_decay=1e-4,
            log_every=100, vis_update_interval=5):
        """
        Train the model using SVI with TraceCausalEffect_ELBO.
        The dashboard is updated every vis_update_interval epochs.
        Also prints out a sample X row for debugging at each epoch.
        """
        # Simple whitening function
        self.whiten = lambda data: (data - data.mean(0)) / (data.std(0) + 1e-6)

        dataset = TensorDataset(x, t, y)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

        num_steps = num_epochs * len(dataloader)
        optim = ClippedAdam({
            "lr": learning_rate,
            "weight_decay": weight_decay,
            "lrd": learning_rate_decay ** (1 / num_steps)
        })
        svi = SVI(self.model, self.guide, optim, TraceCausalEffect_ELBO())

        losses = []
        # Fix a small batch for t-SNE viz
        self._fixed_data = x[:min(200, x.size(0))]

        for epoch in range(num_epochs):
            epoch_loss = 0.0
            for i, (batch_x, batch_t, batch_y) in enumerate(dataloader):
                batch_x = self.whiten(batch_x)
                if i == 0:
                    print(f"[DEBUG] EPOCH {epoch}")
                loss = svi.step(batch_x, batch_t, batch_y, size=len(dataset)) / len(dataset)
                epoch_loss += loss
            losses.append(epoch_loss)
            print(f"Epoch {epoch} loss: {epoch_loss:.4f}")
            if epoch % vis_update_interval == 0:
                current_metrics = self.compute_node_metrics()
                self._update_dashboard(epoch, current_metrics, epoch_loss)
        final_metrics = self.compute_node_metrics()
        self._update_dashboard(num_epochs, final_metrics, losses[-1])
        self._save_final_dashboard("final_dashboard.png")
        return losses

    def _update_dashboard(self, epoch, current_metrics, current_loss):
        self.history["epoch"].append(epoch)
        for node in ["X", "T", "Y", "Z"]:
            self.history["param"][node].append(current_metrics[node])
        self.history["perf"].append(current_loss)
        norm_metrics = {}
        for node in ["X", "T", "Y", "Z"]:
            vals = self.history["param"][node]
            val_min, val_max = min(vals), max(vals)
            denom = (val_max - val_min) + 1e-8
            norm_metrics[node] = (current_metrics[node] - val_min) / denom
        _draw_dag(self.dashboard["dag"], self.G, self.pos, norm_metrics)
        _update_time_series(
            self.dashboard["param"],
            self.history["epoch"],
            self.history["param"],
            "Parameter Metrics",
            "Metric Value"
        )
        _update_time_series(
            self.dashboard["perf"],
            self.history["epoch"],
            {"ELBO": self.history["perf"]},
            "ELBO Loss",
            "Loss"
        )
        with torch.no_grad():
            fixed_x = self._fixed_data
            fixed_t = torch.zeros(fixed_x.size(0), device=fixed_x.device)
            fixed_y = torch.zeros(fixed_x.size(0), device=fixed_x.device)
            latent = self._extract_latent(fixed_x, fixed_t, fixed_y)
            if latent is not None:
                latent_np = latent.detach().cpu().numpy()
                tsne = TSNE(n_components=2, random_state=42)
                tsne_emb = tsne.fit_transform(latent_np)
                _update_tsne(self.dashboard["tsne"], tsne_emb)
        self.dashboard["fig"].canvas.draw()
        plt.pause(0.001)

# ======================
# File: analyze_shifts.py
# ======================

#!/usr/bin/env python3
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

def main():
    # Paths to the data files.
    shifted_path = "data/IHDP/processed_X_pca_shifted.csv"
    original_path = "data/IHDP/processed_X_ihdp_modified.csv"

    # Check if files exist.
    if not os.path.exists(shifted_path) or not os.path.exists(original_path):
        print("Required data files not found. Please ensure that both files exist in 'data/TWINS/'.")
        return

    # Load data as DataFrames.
    df_shifted = pd.read_csv(shifted_path)
    df_original = pd.read_csv(original_path)

    # Check that the data have the same columns.
    if not all(df_original.columns == df_shifted.columns):
        print("Column mismatch between original and shifted data.")
        return

    columns = df_original.columns
    shifted_vars = []
    diff_summary = []

    # Create a directory to save the distribution plots.
    plots_dir = "shift_analysis_plots"
    os.makedirs(plots_dir, exist_ok=True)

    # Loop over each variable (column) and compare distributions.
    for col in columns:
        orig = df_original[col]
        shft = df_shifted[col]

        # Calculate summary statistics.
        orig_mean = orig.mean()
        shft_mean = shft.mean()
        mean_diff = shft_mean - orig_mean
        orig_std = orig.std()
        shft_std = shft.std()
        std_diff = shft_std - orig_std

        # Determine if the variable is shifted.
        # Here we use a threshold: if the absolute mean difference is larger than 10% of the original standard deviation.
        threshold = 0.1 * orig_std if orig_std != 0 else 0
        if abs(mean_diff) > threshold:
            shifted_vars.append(col)

        diff_summary.append({
            "column": col,
            "original_mean": orig_mean,
            "shifted_mean": shft_mean,
            "mean_diff": mean_diff,
            "original_std": orig_std,
            "shifted_std": shft_std,
            "std_diff": std_diff
        })

        # Plot histogram overlay for the variable.
        plt.figure(figsize=(8, 4))
        plt.hist(orig, bins=50, alpha=0.5, density=True, label="Original")
        plt.hist(shft, bins=50, alpha=0.5, density=True, label="Shifted")
        plt.title(f"Distribution Comparison for {col}")
        plt.xlabel(col)
        plt.ylabel("Density")
        plt.legend()
        plt.tight_layout()
        plt.savefig(os.path.join(plots_dir, f"distribution_{col}.png"))
        plt.close()

    # Print summary.
    print("Variables detected as shifted:")
    if shifted_vars:
        for var in shifted_vars:
            print(f"  {var}")
    else:
        print("  None")

    print("\nDetailed Summary (per variable):")
    for entry in diff_summary:
        print(f"{entry['column']}: original_mean={entry['original_mean']:.4f}, shifted_mean={entry['shifted_mean']:.4f}, "
              f"mean_diff={entry['mean_diff']:.4f}, original_std={entry['original_std']:.4f}, shifted_std={entry['shifted_std']:.4f}, "
              f"std_diff={entry['std_diff']:.4f}")

if __name__ == "__main__":
    main()


# ======================
# File: shift_pca.py
# ======================

#!/usr/bin/env python3
"""
shift_pca.py

This script performs PCA on the Twins covariates and then shifts (flips and scales)
the top 3 principal components. The transformation used is:
    new_value = scale_factor * (max + min - original)
for the top 3 components, leaving the remaining components unchanged.
"""

import os
import argparse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

def flip_values(arr, scale_factor=2.0):
    """
    Given a 1D numpy array, return a flipped and scaled version:
    new_value = scale_factor * (max + min - original).
    """
    min_val = np.min(arr)
    max_val = np.max(arr)
    return scale_factor * (max_val + min_val - arr)

def plot_pc_distributions(before, after, pc_index, plot_file):
    """
    Plot overlay histograms for a given principal component (pc_index)
    before and after shifting.
    """
    plt.figure(figsize=(8, 6))
    plt.hist(before, bins=50, alpha=0.5, density=True, label="Before Shift")
    plt.hist(after, bins=50, alpha=0.5, density=True, label="After Shift")
    plt.title(f"PC{pc_index+1} Distribution Before vs. After Shift")
    plt.xlabel(f"PC{pc_index+1} Score")
    plt.ylabel("Density")
    plt.legend()
    plt.tight_layout()
    plt.savefig(plot_file)
    plt.close()
    print(f"Plot saved to {plot_file}")

def main():
    parser = argparse.ArgumentParser(
        description="Perform PCA on Twins covariates and then shift (flip and scale) the top 3 principal components."
    )
    parser.add_argument("--input-file", type=str, default="data/TWINS/processed_X.csv",
                        help="Path to the input covariate CSV file (default: data/TWINS/processed_X.csv)")
    parser.add_argument("--output-file", type=str, default="data/TWINS/processed_X_pca_shifted.csv",
                        help="Path to save the new shifted covariate dataset (default: data/TWINS/processed_X_pca_shifted.csv)")
    parser.add_argument("--n-components", type=int, default=10,
                        help="Number of PCA components to compute (default: 10)")
    parser.add_argument("--plot-dir", type=str, default="pca_shift_plots",
                        help="Directory to save the before/after PC plots (default: pca_shift_plots)")
    parser.add_argument("--scale-factor", type=float, default=2.0,
                        help="Scaling factor to modify the flipped PCs (default: 2.0)")
    args = parser.parse_args()

    if not os.path.exists(args.input_file):
        print(f"Error: Input file '{args.input_file}' does not exist.")
        return

    df = pd.read_csv(args.input_file)
    print(f"Loaded data with shape {df.shape} from {args.input_file}")

    scaler = StandardScaler()
    X_std = scaler.fit_transform(df.values)

    pca = PCA(n_components=args.n_components)
    PCs = pca.fit_transform(X_std)
    print("Explained variance ratios for computed components:")
    for i, ratio in enumerate(pca.explained_variance_ratio_):
        print(f"PC{i+1}: {ratio:.4f}")

    top3_before = PCs[:, :3].copy()

    # Flip and scale the top 3 principal components.
    for i in range(3):
        PCs[:, i] = flip_values(PCs[:, i], scale_factor=args.scale_factor)
    
    top3_after = PCs[:, :3]

    if not os.path.exists(args.plot_dir):
        os.makedirs(args.plot_dir, exist_ok=True)
    for i in range(3):
        plot_file = os.path.join(args.plot_dir, f"PC{i+1}_before_after.png")
        plot_pc_distributions(top3_before[:, i], top3_after[:, i], i, plot_file)

    X_new_std = pca.inverse_transform(PCs)
    X_new = scaler.inverse_transform(X_new_std)

    df_new = pd.DataFrame(X_new, columns=df.columns)

    output_dir = os.path.dirname(args.output_file)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
    df_new.to_csv(args.output_file, index=False)
    print(f"New shifted dataset saved to {args.output_file}")

if __name__ == "__main__":
    main()


# ======================
# File: data.py
# ======================

import torch
import pandas as pd
import numpy as np
from pathlib import Path

##########################
# Twin Data Functions
##########################

def load_twins_data(train_shifted: bool = False,
                    path_x: str = None,
                    path_t: str = "data/TWINS/processed_t.csv",
                    path_y: str = "data/TWINS/processed_y.csv",
                    path_z: str = "data/TWINS/processed_z_p0.1.csv") -> tuple:
    """
    Loads the Twins dataset. Returns X, t, y, Z as torch Tensors.
    If train_shifted is True, loads the shifted covariate file.
    """
    if path_x is None:
        if train_shifted:
            path_x = "data/TWINS/processed_X_covariate_shifted.csv"
        else:
            path_x = "data/TWINS/processed_X.csv"
    # Read data from CSV files.
    X = pd.read_csv(path_x).values
    t = pd.read_csv(path_t).values.squeeze()
    y = pd.read_csv(path_y).values.squeeze()
    Z = pd.read_csv(path_z).values

    X = torch.tensor(X, dtype=torch.float)
    t = torch.tensor(t, dtype=torch.float)
    y = torch.tensor(y, dtype=torch.float)
    Z = torch.tensor(Z, dtype=torch.float)

    total_samples = X.shape[0]
    if total_samples % 2 != 0:
        raise ValueError("Number of samples must be even for Twins data.")

    print(f"Loaded Twins covariates from: {path_x}")
    return X, t, y, Z


def prepare_train_test_split(X: torch.Tensor, t: torch.Tensor, y: torch.Tensor, Z: torch.Tensor,
                             num_data: int, test_size: float, seed: int) -> tuple:
    """
    Given X, t, y, Z, creates a train/test split for the Twins dataset.
    Splitting is done at the twin-pair level to preserve pairing.
    Returns:
      - X_train, t_train, y_train, Z_train (training tensors)
      - X_test, t_test, y_test, Z_test (test tensors)
      - true_ite_train, true_ite_test (computed from observed outcomes)
      - XZ_train, t_train_np, y_train_np (for baseline methods)
      - train_twin0, train_twin1, test_twin0, test_twin1 (index arrays)
    """
    total_samples = X.shape[0]
    N_pairs = total_samples // 2
    sample_size_pairs = num_data // 2

    torch.manual_seed(seed)
    selected_pairs = torch.randperm(N_pairs)[:sample_size_pairs]

    n_test = int(test_size * sample_size_pairs)
    test_pairs = selected_pairs[:n_test]
    train_pairs = selected_pairs[n_test:]

    train_twin0 = 2 * train_pairs
    train_twin1 = 2 * train_pairs + 1
    test_twin0 = 2 * test_pairs
    test_twin1 = 2 * test_pairs + 1

    X_train = torch.cat([X[train_twin0], X[train_twin1]], dim=0)
    t_train = torch.cat([t[train_twin0], t[train_twin1]], dim=0)
    y_train = torch.cat([y[train_twin0], y[train_twin1]], dim=0)
    Z_train = torch.cat([Z[train_twin0], Z[train_twin1]], dim=0)

    X_test = torch.cat([X[test_twin0], X[test_twin1]], dim=0)
    t_test = torch.cat([t[test_twin0], t[test_twin1]], dim=0)
    y_test = torch.cat([y[test_twin0], y[test_twin1]], dim=0)
    Z_test = torch.cat([Z[test_twin0], Z[test_twin1]], dim=0)

    true_ite_train = (y[train_twin1] - y[train_twin0]).numpy()
    true_ite_test = (y[test_twin1] - y[test_twin0]).numpy()

    XZ_train = np.concatenate([X_train.numpy(), Z_train.numpy()], axis=1)
    t_train_np = t_train.numpy()
    y_train_np = y_train.numpy()

    return (X_train, t_train, y_train, Z_train,
            X_test, t_test, y_test, Z_test,
            true_ite_train, true_ite_test,
            XZ_train, t_train_np, y_train_np,
            train_twin0, train_twin1, test_twin0, test_twin1)

    
##########################
# IHDP Data Functions
##########################

def load_ihdp_data(path: str = "data/IHDP/csv/concatenated_ihdp.csv",
                   train_shifted: bool = False) -> tuple:
    """
    Loads the IHDP dataset from the concatenated CSV file.

    The expected columns are: treatment, y_factual, y_cfactual, mu0, mu1, x1...x25.
    (Both factual and counterfactual outcomes are available.)

    Depending on the 'train_shifted' flag, this function loads either the PCA‐shifted
    covariates (for training) or the modified (24-column) covariates (for testing).
    For the latent confounder Z, it attempts to load a default file (flip probability 0.1).

    Returns:
        X: Covariate tensor.
        t: Treatment tensor.
        y: Factual outcome tensor (y_factual).
        y_cf: Counterfactual outcome tensor (y_cfactual).
        Z: Latent confounder tensor.
    """
    df = pd.read_csv(path)
    expected_cols = ["treatment", "y_factual", "y_cfactual", "mu0", "mu1"] + [f"x{i}" for i in range(1, 26)]
    for col in expected_cols:
        if col not in df.columns:
            raise ValueError(f"Missing expected column: {col}")

    t = df["treatment"].values
    y = df["y_factual"].values
    y_cf = df["y_cfactual"].values

    x_mod_file = Path("data/IHDP/processed_X_ihdp_modified.csv")
    x_pca_file = Path("data/IHDP/processed_X_pca_shifted.csv")

    if train_shifted:
        if not x_pca_file.exists():
            raise FileNotFoundError(f"--train-shifted=True but '{x_pca_file}' not found.")
        X = pd.read_csv(x_pca_file).values
        print("Loaded PCA-shifted IHDP covariates from:", x_pca_file)
    else:
        if x_mod_file.exists():
            X = pd.read_csv(x_mod_file).values
            print("Loaded modified IHDP covariates (24 columns) from:", x_mod_file)
        else:
            covariate_cols = [f"x{i}" for i in range(1, 26)]
            X = df[covariate_cols].values
            print("Using original 25-column IHDP covariates from the concatenated CSV.")

    z_file = Path("data/IHDP/processed_Z_ihdp_p0.1.csv")
    if z_file.exists():
        Z = pd.read_csv(z_file).values
        if Z.ndim == 1:
            Z = Z.reshape(-1, 1)
        print("Loaded latent confounder Z from:", z_file)
    else:
        Z = np.zeros((X.shape[0], 1))
        print("No latent confounder file found; using Z=0.")

    X = torch.tensor(X, dtype=torch.float)
    t = torch.tensor(t, dtype=torch.float)
    y = torch.tensor(y, dtype=torch.float)
    y_cf = torch.tensor(y_cf, dtype=torch.float)
    Z = torch.tensor(Z, dtype=torch.float)

    return X, t, y, y_cf, Z

def prepare_train_test_split_ihdp(X: torch.Tensor, t: torch.Tensor, y: torch.Tensor, y_cf: torch.Tensor, Z: torch.Tensor,
                                  test_size: float, seed: int) -> tuple:
    """
    Prepares a random train/test split for IHDP.

    The training set uses the (possibly shifted) covariates as loaded.
    The test set is forced to come from the original unshifted modified covariates.

    This function now computes the true ITE from the available factual and counterfactual outcomes.
    True ITE is computed as:
        if t == 1:  y_factual - y_cfactual
        else:       y_cfactual - y_factual

    Returns a tuple containing:
      - X_train, t_train, y_train, y_cf_train, Z_train (training tensors)
      - X_test, t_test, y_test, y_cf_test, Z_test (test tensors; note X_test is unshifted)
      - true_ite_train, true_ite_test (computed true ITE arrays)
      - XZ_train, t_train_np, y_train_np (for baseline methods)
      - train_idx, test_idx: index arrays for training and testing splits.
    """
    np.random.seed(seed)
    total_samples = X.shape[0]
    indices = np.random.permutation(total_samples)
    n_test = int(test_size * total_samples)
    test_idx = indices[:n_test]
    train_idx = indices[n_test:]

    X_train = X[train_idx]
    t_train = t[train_idx]
    y_train = y[train_idx]
    y_cf_train = y_cf[train_idx]
    Z_train = Z[train_idx]

    X_test = X[test_idx]
    t_test = t[test_idx]
    y_test = y[test_idx]
    y_cf_test = y_cf[test_idx]
    Z_test = Z[test_idx]

    true_ite_train = np.where(t_train.numpy()==1, (y_train - y_cf_train).numpy(), (y_cf_train - y_train).numpy())
    true_ite_test  = np.where(t_test.numpy()==1, (y_test - y_cf_test).numpy(), (y_cf_test - y_test).numpy())

    XZ_train = np.concatenate([X_train.numpy(), Z_train.numpy()], axis=1)
    t_train_np = t_train.numpy()
    y_train_np = y_train.numpy()

    return (X_train, t_train, y_train, y_cf_train, Z_train,
            X_test, t_test, y_test, y_cf_test, Z_test,
            true_ite_train, true_ite_test,
            XZ_train, t_train_np, y_train_np,
            train_idx, test_idx)

if __name__ == "__main__":
    print("Module data.py loaded successfully.")
